communication protocol in telecommunication a communication protocol is a system of rules that allow two or more entities of a communications system to transmit information via any kind of variation of a physical quantity the protocol defines the rules syntax semantics and synchronization of communication and possible error recovery methods protocols may be implemented by hardware software or a combination of both communicating systems use welldefined formats for exchanging various messages each message has an exact meaning intended to elicit a response from a range of possible responses predetermined for that particular situation the specified behavior is typically independent of how it is to be implemented communication protocols have to be agreed upon by the parties involved multiple protocols often describe different aspects of a single communication a group of protocols designed to work together are known as a protocol suite when implemented in software they are a protocol stack internet communication protocols are published by the internet engineering task force ietf the ieee handles wired and wireless networking and the international organization for standardization iso handles other types the itut handles telecommunication protocols and formats for the public switched telephone network pstn as the pstn and internet converge the standards are also being driven towards convergence communicating systems the information exchanged between devices through a network or other media is governed by rules and conventions that can be set out in communication protocol specifications the nature of a communication the actual data exchanged and any statedependent behaviors is defined by these specifications in digital computing systems the rules can be expressed by algorithms and data structures protocols are to communication what algorithms or programming languages are to computations operating systems usually contain a set of cooperating processes that manipulate shared data to communicate with each other this communication is governed by wellunderstood protocols which can be embedded in the process code itself in contrast because there is no shared memory communicating systems have to communicate with each other using a shared transmission medium transmission is not necessarily reliable and individual systems may use different hardware or operating systems to implement a networking protocol the protocol software modules are interfaced with a framework implemented on the machines operating system this framework implements the networking functionality of the operating system when protocol algorithms are expressed in a portable programming language the protocol software may be made operating system independent the best known frameworks are the tcpip model and the osi model at the time the internet was developed abstraction layering had proven to be a successful design approach for both compiler and operating system design and given the similarities between programming languages and communication protocols the originally monolithic networking programs were decomposed into cooperating protocols systems typically do not use a single protocol to handle a transmission instead they use a set of cooperating protocols sometimes called a protocol suite some of the best known protocol suites are tcpip ipxspx x25 ax25 and appletalk the protocols can be arranged based on functionality in groups for instance there is a group of transport protocols the functionalities are mapped onto the layers each layer solving a distinct class of problems relating to for instance application transport internet and network interfacefunctions basic requirements getting the data across a network is only part of the problem for a protocol the data received has to be evaluated in the context of the progress of the conversation a protocol therefore must include rules describing the context these kind of rules are said to express the syntax of the communication other rules determine whether the data is meaningful for the context in which the exchange takes place these kind of rules are said to express the semantics of the communication messages are sent and received on communicating systems to establish communication protocols should therefore specify rules governing the transmission in general much of the following should be addressed data formats for data exchange digital message bitstrings are exchanged the bitstrings are divided in fields and each field carries information relevant to the protocol conceptually the bitstring is divided into two parts called the header and the payload the actual message is carried in the payload the header area contains the fields with relevance to the operation of the protocol bitstrings longer than the maximum transmission unit mtu are divided in pieces of appropriate size address formats for data exchange addresses are used to identify both the sender and the intended receivers the addresses are carried in the header area of the bitstrings allowing the receivers to determine whether the bitstrings are of interest and should be processed or should be ignored a connection between a sender and a receiver can be identified using an address pair sender address receiver address usually some address values have special meanings an all1s address could be taken to mean an addressing of all stations on the network so sending to this address would result in a broadcast on the local network the rules describing the meanings of the address value are collectively called an addressing scheme address mapping sometimes protocols need to map addresses of one scheme on addresses of another scheme for instance to translate a logical ip address specified by the application to an ethernet mac address this is referred to as address mapping routing when systems are not directly connected intermediary systems along the route to the intended receivers need to forward messages on behalf of the sender on the internet the networks are connected using routers the interconnection of networks through routers is called internetworking detection of transmission errors error detection is necessary on networks where data corruption is possible in a common approach crcs of the data area are added to the end of packets making it possible for the receiver to detect differences caused by corruption the receiver rejects the packets on crc differences and arranges somehow for retransmission acknowledgements acknowledgement of correct reception of packets is required for connectionoriented communication acknowledgements are sent from receivers back to their respective senders loss of information timeouts and retries packets may be lost on the network or be delayed in transit to cope with this under some protocols a sender may expect an acknowledgement of correct reception from the receiver within a certain amount of time thus on timeouts the sender may need to retransmit the information direction of information flow direction needs to be addressed if transmissions can only occur in one direction at a time as on halfduplex links or from one sender at time as on a shared medium this is known as media access control arrangements have to be made to accommodate the case of collision or contention where two parties respectively simultaneously transmit or wish to transmit sequence control if long bitstrings are divided in pieces and then sent on the network individually the pieces may get lost or delayed or on some types of networks take different routes to their destination as a result pieces may arrive out of sequence retransmissions can result in duplicate pieces by marking the pieces with sequence information at the sender the receiver can determine what was lost or duplicated ask for necessary retransmissions and reassemble the original message flow control flow control is needed when the sender transmits faster than the receiver or intermediate network equipment can process the transmissions flow control can be implemented by messaging from receiver to sender protocol design systems engineering principles have been applied to create a set of common network protocol design principles design of complex protocols often involves decomposition into simpler cooperating protocols such a set of cooperating protocols is sometimes called a protocol family or a protocol suite within a conceptual framework communicating systems operate concurrently an important aspect of concurrent programming is the synchronization of software for receiving and transmitting messages of communication in proper sequencing concurrent programming has traditionally been a topic in operating systems theory texts the literature presents numerous analogies between computer communication and programming in analogy a transfer mechanism of a protocol is comparable to a central processing unit cpu the framework introduces rules that allow the programmer to design cooperating protocols independently of one another protocols are to computer communication what programming languages are to computation layering figure 2 the tcpip model or internet layering scheme and its relation to some common protocols in modern protocol design protocols are layered to form a protocol stack layering is a design principle which divides the protocol design task into smaller steps each of which accomplishes a specific part interacting with the other parts of the protocol only in a small number of welldefined ways layering allows the parts of a protocol to be designed and tested without a combinatorial explosion of cases keeping each design relatively simple layering also permits familiar protocols to be adapted to unusual circumstances for example the mail protocol can be adapted to send messages to aircraft by changing the v42 modem protocol to the inmars lapd data protocol used by the international marine radio satellites the communication protocols in use in the internet are designed to function in diverse and complex settings internet protocols are designed for simplicity and modularity in interoperating and fit into a coarse hierarchy of functional layers traditionally called the tcpip model or internet protocol suite the name tcpip arose from the first two cooperating protocols the transmission control protocol tcp and the internet protocol ip that resulted from the decomposition of the original transmission control program a monolithic communication protocol into the first two layers of the communication suite this model was expanded to four layers by additional protocols however the internet protocol development has not focussed on the principle of layering as mandatory recipe for communication rather it evolved as a convenient description of modularity and protocol cooperation a different model is the osi seven layer model which was developed internationally as a rigorous reference model for general communication with much stricter rules of protocol interaction and a rigorous layering concept of functionality typically application software is built upon a robust data transport layer underlying this transport layer is a datagram delivery and routing mechanism that is typically connectionless in the internet packet relaying across networks happens over another layer that involves only network link technologies which are often specific to certain physical layer technologies such as ethernet layering provides opportunities to exchange technologies when needed for example protocols are often stacked in a tunneling arrangement to accommodate connection of dissimilar networks for example ip may be tunneled across an asynchronous transfer mode atm network protocol layering figure 3 message flows using a protocol suite black loops show the actual messaging loops red loops are the effective communication between layers enabled by the lower layers protocol layering now forms the basis of protocol design together the layers make up a layering scheme or model computations deal with algorithms and data and communication involves protocols and messages so the analog of a data flow diagram is some kind of message flow diagram to visualize protocol layering and protocol suites a diagram of the message flows in and between two systems a and b is shown in figure 3 the systems both make use of the same protocol suite the vertical flows and protocols are in system and the horizontal message flows and protocols are between systems the message flows are governed by rules and data formats specified by protocols the blue lines therefore mark the boundaries of the horizontal protocol layers the vertical protocols are not layered because they dont obey the protocol layering principle which states that a layered protocol is designed so that layer n at the destination receives exactly the same object sent by layer n at the source the horizontal protocols are layered protocols and all belong to the protocol suite layered protocols allow the protocol designer to concentrate on one layer at a time without worrying about how other layers perform the vertical protocols need not be the same protocols on both systems but they have to satisfy some minimal assumptions to ensure the protocol layering principle holds for the layered protocols this can be achieved using a technique called encapsulation usually a message or a stream of data is divided into small pieces called messages or streams packets ip datagrams or network frames depending on the layer in which the pieces are to be transmitted the pieces contain a header area and a data area the data in the header area identifies the source and the destination on the network of the packet the protocol and other data meaningful to the protocol like crcs of the data to be sent data length and a timestamp the rule enforced by the vertical protocols is that the pieces for transmission are to be encapsulated in the data area of all lower protocols on the sending side and the reverse is to happen on the receiving side the result is that at the lowest level the piece looks like this header1header2header3data and in the layer directly above it header2header3data and in the top layer header3data both on the sending and receiving side this rule therefore ensures that the protocol layering principle holds and effectively virtualizes all but the lowest transmission lines so for this reason some message flows are coloured red in figure 3 to ensure both sides use the same protocol the pieces also carry data identifying the protocol in their header the design of the protocol layering and the network or internet architecture are interrelated so one cannot be designed without the other some of the more important features in this respect of the internet architecture and the network services it provides are described next the internet offers universal interconnection which means that any pair of computers connected to the internet is allowed to communicate each computer is identified by an address on the internet all the interconnected physical networks appear to the user as a single large network this interconnection scheme is called an internetwork or internet conceptually an internet addresses consists of a netid and a hostid the netid identifies a network and the hostid identifies a host the term host is misleading in that an individual computer can have multiple network interfaces each having its own internet address an internet address identifies a connection to the network not an individual computer network technology independence is achieved using the lowlevel address resolution protocol arp which is used to map internet addresses to physical addresses the mapping is called address resolution this way physical addresses are only used by the protocols of the network interface layer figure 4 message flows in the presence of a routerphysical networks are interconnected by routers routers forward packets between interconnected networks making it possible for hosts to reach hosts on other physical networks the message flows between two communicating systems a and b in the presence of a router r are illustrated in figure 4 datagrams are passed from router to router until a router is reached that can deliver the datagram on a physically attached network called direct delivery all networks are treated equal a lan a wan or a pointtopoint link between two computers are all considered as one network a connectionless packet delivery or packetswitched system or service is offered by the internet because it adapts well to different hardware including besteffort delivery mechanisms like the ethernet connectionless delivery means that the messages or streams are divided into pieces that are multiplexed separately on the high speed intermachine connections allowing the connections to be used concurrently each piece carries information identifying the destination the delivery of packets is said to be unreliable because packets may be lost duplicated delayed or delivered out of order without notice to the sender or receiver unreliability arises only when resources are exhausted or underlying networks fail a reliable stream transport service using the unreliable connectionless packet delivery service is defined by the transmission control protocol tcp the services are layered as well and the application programs residing in the layer above it called the application services can make use of tcp software layering having established the protocol layering and the protocols the protocol designer can now resume with the software design the software has a layered organization and its relationship with protocol layering is visualized in figure 5 figure 5 protocol and software layering the software modules implementing the protocols are represented by cubes the information flow between the modules is represented by arrows the top two horizontal red arrows are virtual the blue lines mark the layer boundaries to send a message on system a the top module interacts with the module directly below it and hands over the message to be encapsulated this module reacts by encapsulating the message in its own data area and filling in its header data in accordance with the protocol it implements and interacts with the module below it by handing over this newly formed message whenever appropriate the bottom module directly interacts with the bottom module of system b so the message is sent across on the receiving system b the reverse happens so ultimately and assuming there were no transmission errors or protocol violations etc the message gets delivered in its original form to the topmodule of system b on protocol errors a receiving module discards the piece it has received and reports back the error condition to the original source of the piece on the same layer by handing the error message down or in case of the bottom module sending it across the division of the message or stream of data into pieces and the subsequent reassembly are handled in the layer that introduced the divisionreassembly the reassembly is done at the destination ie not on any intermediate routers tcpip software is organized in four layers application layer at the highest layer the services available across a tcpip internet are accessed by application programs the application chooses the style of transport to be used which can be a sequence of individual messages or a continuous stream of bytes the application program passes data to the transport layer for delivery transport layer the transport layer provides communication from one application to another the transport layer may regulate flow of information and provide reliable transport ensuring that data arrives without error and in sequence to do so the receiving side sends back acknowledgments and the sending side retransmits lost pieces called packets the stream of data is divided into packets by the module and each packet is passed along with a destination address to the next layer for transmission the layer must accept data from many applications concurrently and therefore also includes codes in the packet header to identify the sending and receiving application program internet layer the internet layer handles the communication between machines packets to be sent are accepted from the transport layer along with an identification of the receiving machine the packets are encapsulated in ip datagrams and the datagram headers are filled a routing algorithm is used to determine if the datagram should be delivered directly or sent to a router the datagram is passed to the appropriate network interface for transmission incoming datagrams are checked for validity and the routing algorithm is used to decide whether the datagram should be processed locally or forwarded if the datagram is addressed to the local machine the datagram header is deleted and the appropriate transport protocol for the packet is chosen icmp error and control messages are handled as well in this layer link layer the link layer is responsible for accepting ip datagrams and communicating them on the local network link by whatever technology is suitable tcpip does not concern itself with such details and simply assumes an available facility program translation is divided into four subproblems compiler assembler link editor and loader as a result the translation software is layered as well allowing the software layers to be designed independently noting that the ways to conquer the complexity of program translation could readily be applied to protocols because of the analogy between programming languages and protocols the designers of the tcpip protocol suite were keen on imposing the same layering on the software framework this can be seen in the tcpip layering by considering the translation of a pascal program message that is compiled function of the application layer into an assembler program that is assembled function of the transport layer to object code pieces that is linked function of the internet layer together with library object code routing table by the link editor producing relocatable machine code datagram that is passed to the loader which fills in the memory locations ethernet addresses to produce executable code network frame to be loaded function of the network interface layer into physical memory transmission medium to show just how closely the analogy fits the terms between parentheses in the previous sentence denote the relevant analogs and the terms written cursively denote data representations program translation forms a linear sequence because each layers output is passed as input to the next layer furthermore the translation process involves multiple data representations we the modules below the application layer are generally considered part of the operating system passing data between these modules is much less expensive than passing data between an application program and the transport layer the boundary between application layer and transport layer is called the operating system boundary strict layering strictly adhering to a layered model a practice known as strict layering is not always the best approach to networking disadvantages while the use of protocol layering is today ubiquitous across the field of computer networking it has been historically criticized by many researchers secondly it is common that a protocol implementation at one layer may require data state or addressing information that is only present at another layer thus defeating the point of separating the layers in the first place for example tcp uses the ecn field in the ipv4 header as an indication of congestion ip is a network layer protocol whereas tcp is a transport layer protocol design patterns for application layer protocols there are commonly reoccurring problems that occur in the design and implementation of communication protocols and can be addressed by patterns from several different pattern languages pattern language for applicationlevel communication protocols commdp the first of these pattern languages focuses on the design of protocols and not their implementations the others address issues in either both areas or just the latter formal specification formal methods of describing communication syntax are abstract syntax notation one an iso standard and augmented backusnaur form an ietf standard finite state machine models are used to formally describe the possible interactions of the protocol protocol development for communication to take place protocols have to be agreed upon recall that in digital computing systems the rules can be expressed by algorithms and datastructures raising the opportunity for hardware independence expressing the algorithms in a portable programming language makes the protocol software operating system independent the source code could be considered a protocol specification this form of specification however is not suitable for the parties involved for one thing this would enforce a source on all parties and for another proprietary software producers would not accept this by describing the software interfaces of the modules on paper and agreeing on the interfaces implementers are free to do it their way this is referred to as source independence by specifying the algorithms on paper and detailing hardware dependencies in an unambiguous way a paper draft is created that when adhered to and published ensures interoperability between software and hardware such a paper draft can be developed into a protocol standard by getting the approval of a standards organization to get the approval the paper draft needs to enter and successfully complete the standardization process this activity is referred to as protocol development the members of the standards organization agree to adhere to the standard on a voluntary basis often the members are in control of large marketshares relevant to the protocol and in many cases standards are enforced by law or the government because they are thought to serve an important public interest so getting approval can be very important for the protocol it should be noted though that in some cases protocol standards are not sufficient to gain widespread acceptance ie sometimes the source code needs to be disclosed and enforced by law or the government in the interest of the public the need for protocol standards the need for protocol standards can be shown by looking at what happened to the bisync protocol bsc invented by ibm bsc is an early linklevel protocol used to connect two separate nodes it was originally not intended to be used in a multinode network but doing so revealed several deficiencies of the protocol in the absence of standardization manufacturers and organizations felt free to enhance the protocol creating incompatible versions on their networks in some cases this was deliberately done to discourage users from using equipment from other manufacturers there are more than 50 variants of the original bisync protocol one can assume that a standard would have prevented at least some of this from happening in some cases protocols gain market dominance without going through a standardization process such protocols are referred to as de facto standards de facto standards are common in emerging markets niche markets or markets that are monopolized or oligopolized they can hold a market in a very negative grip especially when used to scare away competition from a historical perspective standardization should be seen as a measure to counteract the illeffects of de facto standards positive exceptions exist a de facto standard operating system like gnulinux does not have this negative grip on its market because the sources are published and maintained in an open way thus inviting competition standardization is therefore not the only solution for open systems interconnection standards organizations some of the standards organizations of relevance for communication protocols are the international organization for standardization iso the international telecommunication union itu the institute of electrical and electronics engineers ieee and the internet engineering task force ietf the ietf maintains the protocols in use on the internet the ieee controls many software and hardware protocols in the electronics industry for commercial and consumer devices the itu is an umbrella organization of telecommunication engineers designing the public switched telephone network pstn as well as many radio communication systems for marine electronics the nmea standards are used the world wide web consortium w3c produces protocols and standards for web technologies international standards organizations are supposed to be more impartial than local organizations with a national or commercial selfinterest to consider standards organizations also do research and development for standards of the future in practice the standards organizations mentioned cooperate closely with each other the standardization process the standardization process starts off with iso commissioning a subcommittee workgroup the workgroup issues working drafts and discussion documents to interested parties including other standards bodies in order to provoke discussion and comments this will generate a lot of questions much discussion and usually some disagreement on what the standard should provide and if it can satisfy all needs usually not all conflicting views should be taken into account often by way of compromise to progress to a draft proposal of the working group the draft proposal is discussed by the member countries standard bodies and other organizations within each country comments and suggestions are collated and national views will be formulated before the members of iso vote on the proposal if rejected the draft proposal has to consider the objections and counterproposals to create a new draft proposal for another vote after a lot of feedback modification and compromise the proposal reaches the status of a draft international standard and ultimately an international standard the process normally takes several years to complete the original paper draft created by the designer will differ substantially from the standard and will contain some of the following features various optional modes of operation for example to allow for setup of different packet sizes at startup time because the parties could not reach consensus on the optimum packet size parameters that are left undefined or allowed to take on values of a defined set at the discretion of the implementor this often reflects conflicting views of some of the members parameters reserved for future use reflecting that the members agreed the facility should be provided but could not reach agreement on how this should be done in the available time various inconsistencies and ambiguities will inevitably be found when implementing the standard international standards are reissued periodically to handle the deficiencies and reflect changing views on the subject osi standardization a lesson learned from arpanet the predecessor of the internet was that standardization of protocols is not enough this gave rise to the osi open systems interconnection reference model rmosi which is used as a framework for the design of standard protocols and services conforming to the various layer specifications in the osi model communicating systems are assumed to be connected by an underlying physical medium providing a basic and unspecified transmission mechanism the layers above it are numbered from one to seven the nth layer is referred to as nlayer each layer provides service to the layer above it or at the top to the application process using the services of the layer immediately below it the layers communicate with each other by means of an interface called a service access point corresponding layers at each system are called peer entities to communicate two peer entities at a given layer use an nprotocol which is implemented by using services of the n1layer when systems are not directly connected intermediate peer entities called relays are used an address uniquely identifies a service access point the address naming domains need not be restricted to one layer so it is possible to use just one naming domain for all layers for each layer there are two types of standards protocol standards defining how peer entities at a given layer communicate and service standards defining how a given layer communicates with the layer above it in the original version of rmosi the layers and their functionality are from highest to lowest layer the application layer may provide the following services to the application processes identification of the intended communication partners establishment of the necessary authority to communicate determination of availability and authentication of the partners agreement on privacy mechanisms for the communication agreement on responsibility for error recovery and procedures for ensuring data integrity synchronization between cooperating application processes identification of any constraints on syntax eg character sets and data structures determination of cost and acceptable quality of service selection of the dialogue discipline including required logon and logoff procedures the presentation layer may provide the following services to the application layer a request for the establishment of a session data transfer negotiation of the syntax to be used between the application layers any necessary syntax transformations formatting and special purpose transformations eg data compression and data encryption the session layer may provide the following services to the presentation layer establishment and release of session connections normal and expedited data exchange a quarantine service which allows the sending presentation entity to instruct the receiving session entity not to release data to its presentation entity without permission interaction management so presentation entities can control whose turn it is to perform certain control functions resynchronization of a session connection reporting of unrecoverable exceptions to the presentation entity the transport layer provides reliable and transparent data transfer in a costeffective way as required by the selected quality of service it may support the multiplexing of several transport connections on to one network connection or split one transport connection into several network connections the network layer does the setup maintenance and release of network paths between transport peer entities when relays are needed routing and relay functions are provided by this layer the quality of service is negotiated between network and transport entities at the time the connection is set up this layer is also responsible for network congestion control the data link layer does the setup maintenance and release of data link connections errors occurring in the physical layer are detected and may be corrected errors are reported to the network layer the exchange of data link units including flow control is defined by this layer the physical layer describes details like the electrical characteristics of the physical connection the transmission techniques used and the setup maintenance and clearing of physical connections in contrast to the tcpip layering scheme which assumes a connectionless network rmosi assumed a connectionoriented network connectionoriented networks are more suitable for wide area networks and connectionless networks are more suitable for local area networks using connections to communicate implies some form of session and virtual circuits hence the in the tcpip model lacking session layer the constituent members of iso were mostly concerned with wide area networks so development of rmosi concentrated on connection oriented networks and connectionless networks were only mentioned in an addendum to rmosi at the time the ietf had to cope with this and the fact that the internet needed protocols which simply were not there as a result the ietf developed its own standardization process based on rough consensus and running code the standardization process is described by rfc2026 nowadays the ietf has become a standards organization for the protocols in use on the internet rmosi has extended its model to include connectionless services and because of this both tcp and ip could be developed into international standards taxonomies classification schemes for protocols usually focus on domain of use and function as an example of domain of use connectionoriented protocols and connectionless protocols are used on connectionoriented networks and connectionless networks respectively for an example of function consider a tunneling protocol which is used to encapsulate packets in a highlevel protocol so the packets can be passed across a transport system using the highlevel protocol a layering scheme combines both function and domain of use the dominant layering schemes are the ones proposed by the ietf and by iso despite the fact that the underlying assumptions of the layering schemes are different enough to warrant distinguishing the two it is a common practice to compare the two by relating common protocols to the layers of the two schemes for an example of this practice see lists of network protocols the layering scheme from the ietf is called internet layering or tcpip layering the functionality of the layers has been described in the section on software layering and an overview of protocols using this scheme is given in the article on internet protocols the layering scheme from iso is called the osi model or iso layering the functionality of the layers has been described in the section on the future of standardization and an overview of protocols using this scheme is given in the article on osi protocols in networking equipment configuration a termofart distinction is often drawn the term protocol strictly refers to the transport layer and the term service refers to protocols utilizing a protocol for transport in the common case of the tcp and udp protocols services are distinguished by their port numbers conformance to these port numbers is voluntary so in content inspection systems the term service strictly refers to port numbers and the term application is often used to refer to protocols identified through inspection signatures protocols upon which transport layer relies like ipv4 are distinguished by their address family lists of network protocols application programming interface notes bibliography radia perlman interconnections bridges routers switches and internetworking protocols 2nd edition addisonwesley 1999 isbn0201634481 in particular ch 18 on network design folklore which is also available online at httpwwwinformitcomarticlesarticleaspxp20482 gerard j holzmann design and validation of computer protocols prentice hall 1991 isbn0135399254 also available online at httpspinrootcomspindocbook91html douglas e comer 2000 internetworking with tcpip principles protocols and architecture 4th ed prentice hall isbn0130183806 in particular ch11 protocol layering also has a rfc guide and a glossary of internetworking terms and abbreviations internet engineering task force abbr ietf 1989 rfc1122 requirements for internet hosts communication layers r braden ed available online at httptoolsietforghtmlrfc1122 describes tcpip to the implementors of protocolsoftware in particular the introduction gives an overview of the design goals of the suite m benari 1982 principles of concurrent programming 10th print prentice hall international isbn0137010788 car hoare 1985 communicating sequential processes 10th print prentice hall international isbn0131532715 available online via httpwwwusingcspcom rd tennent 1981 principles of programming languages 10th print prentice hall international isbn0137098731 brian w marsden 1986 communication network protocols 2nd edition chartwell bratt isbn0862381061 andrew s tanenbaum 1984 structured computer organization 10th print prentice hall international isbn0138546053 radia perlman interconnections bridges routers switches and internetworking protocols 2nd edition addisonwesley 1999 isbn0201634481 in particular ch 18 on network design folklore gerard j holzmann design and validation of computer protocols prentice hall 1991 isbn0135399254 also available online at httpspinrootcomspindocbook91html javvins protocol dictionary overview of protocols in telecontrol field with osi reference model pdfchart showing the protocols and the osi reference layer blog to discuss ideas about modeling and testing of communication protocols vtetelecommunicationshistory beacon broadcasting cable protection system cable tv communications satellite computer network drums electrical telegraph fax heliographs hydraulic telegraph internet mass media mobile phone optical telecommunication optical telegraphy pager photophone prepay mobile phone radio radiotelephone satellite communications semaphore smartphone smoke signals telecommunications history telautograph telegraphy teleprinter teletype telephone the telephone cases television timeline of communication technology undersea telegraph line videoconferencing videophone videotelephony whistled languagepioneers edwin howard armstrong john logie baird paul baran alexander graham bell tim bernerslee jagadish chandra bose vint cerf claude chappe donald davies lee de forest philo farnsworth reginald fessenden elisha gray erna schneider hoover charles k kao hedy lamarr innocenzo manzetti guglielmo marconi antonio meucci radia perlman alexander stepanovich popov johann philipp reis nikola tesla camille tissot alfred vail charles wheatstone vladimir k zworykin transmissionmedia coaxial cable fiberoptic communication optical fiber freespace optical communication molecular communication radio waves transmission line network topologyand switching links nodes terminal node network switchingcircuit packet telephone exchange multiplexing spacedivision frequencydivision timedivision polarizationdivision orbital angularmomentum codedivision networks arpanet bitnet cellular network computer cyclades ethernet fidonet internet isdn lan mobile ngn npl network public switched telephone radio telecommunications equipment television telex wan wireless world wide web category list portal commons wikiproject vtemajor fields of computer sciencenote this template roughly follows the 2012 acm computing classification systemhardware printed circuit board peripheral integrated circuit very large scale integration systems on chip socs energy consumption green computing electronic design automation hardware acceleration computer systemsorganization computer architecture embedded system realtime computing dependability networks network architecture network protocol network components network scheduler network performance evaluation network service software organization interpreter middleware virtual machine operating system software quality software notationsand tools programming paradigm programming language compiler domainspecific language modeling language software framework integrated development environment software configuration management software library software repository software development software development process requirements analysis software design software construction software deployment software maintenance programming team opensource model theory of computation model of computation formal language automata theory computational complexity theory logic semantics algorithms algorithm design analysis of algorithms algorithmic efficiency randomized algorithm computational geometry mathematicsof computing discrete mathematics probability statistics mathematical software information theory mathematical analysis numerical analysis informationsystems database management system information storage systems enterprise information system social information systems geographic information system decision support system process control system multimedia information system data mining digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion detection system hardware security network security information security application security humancomputerinteraction interaction design social computing ubiquitous computing visualization accessibility concurrency concurrent computing parallel computing distributed computing multithreading multiprocessing artificialintelligence natural language processing knowledge representation and reasoning computer vision automated planning and scheduling search methodology control method philosophy of artificial intelligence distributed artificial intelligence machine learning supervised learning unsupervised learning reinforcement learning multitask learning crossvalidation graphics animation rendering image manipulation graphics processing unit mixed reality virtual reality image compression solid modeling appliedcomputing ecommerce enterprise software computational mathematics computational physics computational chemistry computational biology computational social science computational engineering computational healthcare digital art electronic publishing cyberwarfare electronic voting video games word processing operations research educational technology document management book category portal wikiproject commons authority control lccn sh85029512 ndl 00828222 