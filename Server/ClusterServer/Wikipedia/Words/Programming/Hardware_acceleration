hardware acceleration for hardware accelerators in startup companies see seed accelerator in computing hardware acceleration is the use of computer hardware specially made to perform some functions more efficiently than is possible in software running on a generalpurpose cpu any transformation of data or routine that can be computed can be calculated purely in software run on a generic cpu purely in custommade hardware or in some mix of both an operation can be computed faster in applicationspecific hardware designed or programmed to compute the operation than specified in software and performed on a generalpurpose computer processor each approach has advantages and disadvantages the implementation of computing tasks in hardware to decrease latency and increase throughput is known as hardware acceleration typical advantages of software include more rapid development leading to faster times to market lower nonrecurring engineering costs heightened portability and ease of updating features or patching bugs at the cost of overhead to compute general operations advantages of hardware include speedup reduced power consumption hardware acceleration is advantageous for performance and practical when the functions are fixed so updates are not as needed as in software solutions with the advent of reprogrammable logic devices such as fpgas the restriction of hardware acceleration to fully fixed algorithms is easing in the 2010s decade allowing hardware acceleration to be applied to problem domains requiring modification to algorithms and processing control flow overview integrated circuits can be created to perform arbitrary operations on analog and digital signals most often in computing signals are digital and can be interpreted as binary number data computer hardware and software operate on information in binary representation to perform computing this is accomplished by calculating boolean functions on the bits of input and outputting the result to some output device downstream for storage or further processing either software or hardware can compute any computable function custom hardware offers higher performance per watt for the same functions that can be specified in software hardware description languages hdls such as verilog and vhdl can model the same semantics as software and synthesize the design into a netlist that can be programmed to an fpga or composed into logic gates of an applicationspecific integrated circuit the vast majority of softwarebased computing occurs on machines implementing the von neumann architecture collectively known as storedprogram computers computer programs are stored as data and executed by processors typically one or more cpu cores such processors must fetch and decode instructions as well as data operands from memory as part of the instruction cycle to execute the instructions constituting the software program relying on a common cache for code and data leads to the von neumann bottleneck a fundamental limitation on the throughput of software on processors implementing the von neumann architecture even in the modified harvard architecture where instructions and data have separate caches in the memory hierarchy there is overhead to decoding instruction opcodes and multiplexing available execution units on a microprocessor or microcontroller leading to low circuit utilization intels hyperthreading technology provides simultaneous multithreading by exploiting underutilization of available processor functional units and instruction level parallelism between different hardware threads hardware execution units do not in general rely on the von neumann or modified harvard architectures and do not need to perform the instruction fetch and decode steps of an instruction cycle and incur their overhead if needed calculations are specified in a register transfer level hardware design the time and circuit area costs of the instruction fetch and decoding stages can be reclaimed this saves time power and circuit area allowing the reclaimed resources to be used for increased parallelism possibly for multiple functions as well as increased inputoutput capabilities at the opportunity cost of less generalpurpose utility additionally greater rtl customization of hardware designs allows emerging architectures such as inmemory computing transport triggered architectures tta and networksonchip noc to further benefit from increased locality of data to execution context thereby reducing computing and communication latency between modules and functional units custom hardware is limited in parallel processing capability only by the area and logic blocks available on the integrated circuit die similarly specialized functional units can be composed in parallel as in digital signal processing without being embedded in a processor ip core therefore hardware acceleration is often employed for repetitive fixed tasks involving little conditional branching especially on large amounts of data this is how nvidias cuda line of gpus are implemented example tasks accelerated summing two arrays into a third array this section is empty you can help by adding to it october 2018 summing one million integers suppose we wish to compute the sum of 2 20 1 048 576 displaystyle 2201048576 integers assuming large integers are available as bignum large enough to hold the sum this can be done in software by specifying constexpr int n 20 constexpr int twotothen 1 n bignum arraysumconst stdarrayint twotothen ints bignum result 0 for stdsizet i 0 i twotothen i result ints return result this algorithm is linear time o n textstyle mathcal oleftnright in big o notation in hardware with sufficient area on chip calculation can be parallelized to take only 20 time steps using the prefix sum algorithm the algorithm requires only logarithmic time o log n textstyle mathcal oleftlog nright and o 1 textstyle mathcal oleft1right space as an inplace algorithmparameter int n 20 parameter int twotothen 1 n function int arraysum input int array begin for genvar i 0 i n i begin for genvar j 0 j twotothen j begin if j 1 i begin array end end end return array end endfunction this example takes advantage of the greater parallel resources available in applicationspecific hardware than most software and generalpurpose computing paradigms and architectures stream processing this section needs expansion you can help by adding to it october 2018 hardware acceleration can be applied to stream processing applications examples of hardware acceleration include bit blit acceleration functionality in graphics processing units gpus use of memristors for accelerating neural networks the hardware that performs the acceleration may be part of a generalpurpose cpu or a separate unit in the second case it is referred to as a hardware accelerator or often more specifically as a 3d accelerator cryptographic accelerator etc traditionally processors were sequential instructions are executed one by one and were designed to run general purpose algorithms controlled by instruction fetch for example moving temporary results to and from a register file hardware accelerators improve the execution of a specific algorithm by allowing greater concurrency having specific datapaths for its temporary variables and reducing the overhead of instruction control in the fetchdecodeexecute cycle modern processors are multicore and often feature parallel simd units however hardware acceleration still yields benefits hardware acceleration is suitable for any computationintensive algorithm which is executed frequently depending upon the granularity hardware acceleration can vary from a small functional unit to a large functional block like motion estimation in mpeg2 hardware acceleration units by application application hardware accelerator acronym computer graphics generalpurpose tasks nvidia graphics cards ray tracing graphics processing unit generalpurpose computing on gpu cuda architecture raytracing hardware gpu gpgpu cuda na digital signal processing digital signal processor dsp analog signal processing fieldprogrammable analog array fieldprogrammable rf fpaa fprf sound processing sound card and sound card mixer na computer networking on a chip tcp inputoutput network processor and network interface controller network on a chip tcp offload engine io acceleration technology npu and nic noc tcpoe or toe ioat or ioat cryptography encryption isa ssltls attack random number generation cryptographic accelerator and secure cryptoprocessor hardwarebased encryption aes instruction set ssl acceleration custom hardware attack hardware random number generator na artificial intelligence machine visioncomputer vision neural networks brain simulation ai accelerator vision processing unit physical neural network neuromorphic engineering na vpu pnn na multilinear algebra tensor processing unit tpu physics simulation physics processing unit ppu regular expressions regular expression coprocessor na data compression data compression accelerator na inmemory processing network on a chip and systolic array noc na any computing task computer hardware fieldprogrammable gate arrays applicationspecific integrated circuits complex programmable logic devices systemsonchip multiprocessor systemonchip programmable systemonchip hw sometimes fpga asic cpld soc mpsoc psoc coprocessor directx video acceleration dxva direct memory access dma highlevel synthesis c to hdl flow to hdl soft microprocessor flynns taxonomy of parallel computer architectures single instruction multiple data simd single instruction multiple threads simt multiple instructions multiple data mimd computer for operations with functions vtehardware accelerationtheory universal turing machine parallel computing distributed computing applications gpu gpgpu directx audio digital signal processing hardware random number generation artificial intelligence cryptography ssl machine vision custom hardware attack scrypt networking implementations highlevel synthesis c to hdl fpga asic cpld system on chip network on chip architectures data flow transport triggered multicore manycore heterogeneous inmemory computing systolic array neuromorphic related programmable logic processor design chronology digital electronics virtualization hardware emulation logic synthesis embedded systems vtegraphics processing unitgpu adreno apple geforce quadro infinitereality intel gt mali powervr radeon pro voodoo architecture compute kernel graphics pipeline geometry vertex highdynamicrange rendering multiplyaccumulate operation rasterisation raytracing simd simt tessellation tiled rendering transform clipping and lighting unified shader model components shader unit texture mapping unit render output unit tensor unit inputoutput memory management unit stream processor geometry processor video display controller video processing unit memory direct memory access framebuffer gddr sdram gddr3 gddr4 gddr5 gddr6 high bandwidth memory memory bandwidth memory controller shared graphics memory form factor ip core discrete graphics clustering switching external graphics integrated graphics system on a chip performance clock rate display resolution fillrate pixels texels flops frame rate performance per watt transistor count misc asic gpgpu graphics library hardware acceleration image processing parallel computing vector processor video codec vliw 